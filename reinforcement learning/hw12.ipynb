{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "hw12_reinforcement_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp30SB4bxeQb"
      },
      "source": [
        "# **Homework 12 - Reinforcement Learning**\n",
        "\n",
        "若有任何問題，歡迎來信至助教信箱 ntu-ml-2021spring-ta@googlegroups.com\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXsnCWPtWSNk"
      },
      "source": [
        "## 前置作業\n",
        "\n",
        "首先我們需要安裝必要的系統套件及 PyPi 套件。\n",
        "gym 這個套件由 OpenAI 所提供，是一套用來開發與比較 Reinforcement Learning 演算法的工具包（toolkit）。\n",
        "而其餘套件則是為了在 Notebook 中繪圖所需要的套件。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac932H-4lFkr",
        "outputId": "d98ed37b-24ed-451e-f286-9120f1a1215b"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jun  7 05:29:58 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e2bScpnkVbv",
        "outputId": "29d72f69-27b6-41c5-913f-8d2fc32d1c18"
      },
      "source": [
        "!apt update\n",
        "!apt -q install python-opengl xvfb -y\n",
        "!pip -q install gym[box2d]==0.18.3 pyvirtualdisplay tqdm numpy==1.19.5 torch==1.8.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 14.2 kB/88.7\u001b[0m\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\u001b[0m\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r                                                                               \r0% [Waiting for headers] [Waiting for headers] [Waiting for headers]\u001b[0m\u001b[33m\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers] [Wait\u001b[0m\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r                                                                               \r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers]\u001b[0m\r                                                                         \rHit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "\u001b[33m\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to ppa.launchpa\u001b[0m\r                                                                               \rHit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 2s (106 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "47 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "python-opengl is already the newest version (3.1.0+dfsg-1).\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.9).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 47 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_-i3cdoYsks"
      },
      "source": [
        "接下來，設置好 virtual display，並引入所有必要的套件。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl2nREINDLiw"
      },
      "source": [
        "%%capture\n",
        "from pyvirtualdisplay import Display\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVu9-Vdrl4E3"
      },
      "source": [
        "# 請不要更改 random seed !!!!\n",
        "# 不然在judgeboi上 你的成績不會被reproduce !!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV9i8i2YkRbO"
      },
      "source": [
        "seed = 543 # Do not change this\n",
        "def fix(env, seed):\n",
        "  env.seed(seed)\n",
        "  env.action_space.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)\n",
        "  torch.set_deterministic(True)\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He0XDx6bzjgC"
      },
      "source": [
        "最後，引入 OpenAI 的 gym，並建立一個 [Lunar Lander](https://gym.openai.com/envs/LunarLander-v2/) 環境。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_4-xJcbBt09"
      },
      "source": [
        "%%capture\n",
        "import gym\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "env = gym.make('LunarLander-v2')\n",
        "\n",
        "fix(env, seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmiAOfqRwRX5"
      },
      "source": [
        "import time\n",
        "start = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcMjEUWTBEEB",
        "outputId": "7a6f8e52-eb6c-40c5-808d-d312ccb497b6"
      },
      "source": [
        "!pip freeze"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "absl-py==0.12.0\n",
            "alabaster==0.7.12\n",
            "albumentations==0.1.12\n",
            "altair==4.1.0\n",
            "appdirs==1.4.4\n",
            "argon2-cffi==20.1.0\n",
            "arviz==0.11.2\n",
            "astor==0.8.1\n",
            "astropy==4.2.1\n",
            "astunparse==1.6.3\n",
            "async-generator==1.10\n",
            "atari-py==0.2.9\n",
            "atomicwrites==1.4.0\n",
            "attrs==21.2.0\n",
            "audioread==2.1.9\n",
            "autograd==1.3\n",
            "Babel==2.9.1\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.6.3\n",
            "bleach==3.3.0\n",
            "blis==0.4.1\n",
            "bokeh==2.3.2\n",
            "Bottleneck==1.3.2\n",
            "box2d-py==2.3.8\n",
            "branca==0.4.2\n",
            "bs4==0.0.1\n",
            "CacheControl==0.12.6\n",
            "cached-property==1.5.2\n",
            "cachetools==4.2.2\n",
            "catalogue==1.0.0\n",
            "certifi==2021.5.30\n",
            "cffi==1.14.5\n",
            "cftime==1.5.0\n",
            "chardet==3.0.4\n",
            "click==7.1.2\n",
            "cloudpickle==1.3.0\n",
            "cmake==3.12.0\n",
            "cmdstanpy==0.9.5\n",
            "colorcet==2.0.6\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "contextlib2==0.5.5\n",
            "convertdate==2.3.2\n",
            "coverage==3.7.1\n",
            "coveralls==0.5\n",
            "crcmod==1.7\n",
            "cufflinks==0.17.3\n",
            "cvxopt==1.2.6\n",
            "cvxpy==1.0.31\n",
            "cycler==0.10.0\n",
            "cymem==2.0.5\n",
            "Cython==0.29.23\n",
            "daft==0.0.4\n",
            "dask==2.12.0\n",
            "datascience==0.10.6\n",
            "debugpy==1.0.0\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "descartes==1.1.0\n",
            "dill==0.3.3\n",
            "distributed==1.25.3\n",
            "dlib==19.18.0\n",
            "dm-tree==0.1.6\n",
            "docopt==0.6.2\n",
            "docutils==0.17.1\n",
            "dopamine-rl==1.0.5\n",
            "earthengine-api==0.1.269\n",
            "easydict==1.9\n",
            "EasyProcess==0.3\n",
            "ecos==2.0.7.post1\n",
            "editdistance==0.5.3\n",
            "en-core-web-sm==2.2.5\n",
            "entrypoints==0.3\n",
            "ephem==3.7.7.1\n",
            "et-xmlfile==1.1.0\n",
            "fa2==0.3.5\n",
            "fastai==1.0.61\n",
            "fastdtw==0.3.4\n",
            "fastprogress==1.0.0\n",
            "fastrlock==0.6\n",
            "fbprophet==0.7.1\n",
            "feather-format==0.4.1\n",
            "filelock==3.0.12\n",
            "firebase-admin==4.4.0\n",
            "fix-yahoo-finance==0.0.22\n",
            "Flask==1.1.4\n",
            "flatbuffers==1.12\n",
            "folium==0.8.3\n",
            "future==0.16.0\n",
            "gast==0.4.0\n",
            "GDAL==2.2.2\n",
            "gdown==3.6.4\n",
            "gensim==3.6.0\n",
            "geographiclib==1.50\n",
            "geopy==1.17.0\n",
            "gin-config==0.4.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-api-core==1.26.3\n",
            "google-api-python-client==1.12.8\n",
            "google-auth==1.31.0\n",
            "google-auth-httplib2==0.0.4\n",
            "google-auth-oauthlib==0.4.4\n",
            "google-cloud-bigquery==1.21.0\n",
            "google-cloud-bigquery-storage==1.1.0\n",
            "google-cloud-core==1.0.3\n",
            "google-cloud-datastore==1.8.0\n",
            "google-cloud-firestore==1.7.0\n",
            "google-cloud-language==1.2.0\n",
            "google-cloud-storage==1.18.1\n",
            "google-cloud-translate==1.5.0\n",
            "google-colab==1.0.0\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==0.4.1\n",
            "googleapis-common-protos==1.53.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.10.1\n",
            "greenlet==1.1.0\n",
            "grpcio==1.34.1\n",
            "gspread==3.0.1\n",
            "gspread-dataframe==3.0.8\n",
            "gym==0.18.3\n",
            "h5py==3.1.0\n",
            "HeapDict==1.0.1\n",
            "hijri-converter==2.1.2\n",
            "holidays==0.10.5.2\n",
            "holoviews==1.14.4\n",
            "html5lib==1.0.1\n",
            "httpimport==0.5.18\n",
            "httplib2==0.17.4\n",
            "httplib2shim==0.0.3\n",
            "humanize==0.5.1\n",
            "hyperopt==0.1.2\n",
            "ideep4py==2.0.0.post3\n",
            "idna==2.10\n",
            "imageio==2.4.1\n",
            "imagesize==1.2.0\n",
            "imbalanced-learn==0.4.3\n",
            "imblearn==0.0\n",
            "imgaug==0.2.9\n",
            "importlib-metadata==4.5.0\n",
            "importlib-resources==5.1.4\n",
            "imutils==0.5.4\n",
            "inflect==2.1.0\n",
            "iniconfig==1.1.1\n",
            "install==1.3.4\n",
            "intel-openmp==2021.2.0\n",
            "intervaltree==2.1.0\n",
            "ipykernel==4.10.1\n",
            "ipython==5.5.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.3.9\n",
            "ipywidgets==7.6.3\n",
            "itsdangerous==1.1.0\n",
            "jax==0.2.13\n",
            "jaxlib==0.1.66+cuda110\n",
            "jdcal==1.4.1\n",
            "jedi==0.18.0\n",
            "jieba==0.42.1\n",
            "Jinja2==2.11.3\n",
            "joblib==1.0.1\n",
            "jpeg4py==0.1.4\n",
            "jsonschema==2.6.0\n",
            "jupyter==1.0.0\n",
            "jupyter-client==5.3.5\n",
            "jupyter-console==5.2.0\n",
            "jupyter-core==4.7.1\n",
            "jupyterlab-pygments==0.1.2\n",
            "jupyterlab-widgets==1.0.0\n",
            "kaggle==1.5.12\n",
            "kapre==0.3.5\n",
            "Keras==2.4.3\n",
            "keras-nightly==2.5.0.dev2021032900\n",
            "Keras-Preprocessing==1.1.2\n",
            "keras-vis==0.4.1\n",
            "kiwisolver==1.3.1\n",
            "korean-lunar-calendar==0.2.1\n",
            "librosa==0.8.1\n",
            "lightgbm==2.2.3\n",
            "llvmlite==0.34.0\n",
            "lmdb==0.99\n",
            "LunarCalendar==0.0.9\n",
            "lxml==4.2.6\n",
            "Markdown==3.3.4\n",
            "MarkupSafe==2.0.1\n",
            "matplotlib==3.2.2\n",
            "matplotlib-inline==0.1.2\n",
            "matplotlib-venn==0.11.6\n",
            "missingno==0.4.2\n",
            "mistune==0.8.4\n",
            "mizani==0.6.0\n",
            "mkl==2019.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==8.8.0\n",
            "moviepy==0.2.3.5\n",
            "mpmath==1.2.1\n",
            "msgpack==1.0.2\n",
            "multiprocess==0.70.11.1\n",
            "multitasking==0.0.9\n",
            "murmurhash==1.0.5\n",
            "music21==5.5.0\n",
            "natsort==5.5.0\n",
            "nbclient==0.5.3\n",
            "nbconvert==5.6.1\n",
            "nbformat==5.1.3\n",
            "nest-asyncio==1.5.1\n",
            "netCDF4==1.5.6\n",
            "networkx==2.5.1\n",
            "nibabel==3.0.2\n",
            "nltk==3.2.5\n",
            "notebook==5.3.1\n",
            "numba==0.51.2\n",
            "numexpr==2.7.3\n",
            "numpy==1.19.5\n",
            "nvidia-ml-py3==7.352.0\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.1.1\n",
            "okgrade==0.4.3\n",
            "opencv-contrib-python==4.1.2.30\n",
            "opencv-python==4.1.2.30\n",
            "openpyxl==2.5.9\n",
            "opt-einsum==3.3.0\n",
            "osqp==0.6.2.post0\n",
            "packaging==20.9\n",
            "palettable==3.3.0\n",
            "pandas==1.1.5\n",
            "pandas-datareader==0.9.0\n",
            "pandas-gbq==0.13.3\n",
            "pandas-profiling==1.4.1\n",
            "pandocfilters==1.4.3\n",
            "panel==0.11.3\n",
            "param==1.10.1\n",
            "parso==0.8.2\n",
            "pathlib==1.0.1\n",
            "patsy==0.5.1\n",
            "pexpect==4.8.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==7.1.2\n",
            "pip-tools==4.5.1\n",
            "plac==1.1.3\n",
            "plotly==4.4.1\n",
            "plotnine==0.6.0\n",
            "pluggy==0.7.1\n",
            "pooch==1.4.0\n",
            "portpicker==1.3.9\n",
            "prefetch-generator==1.0.1\n",
            "preshed==3.0.5\n",
            "prettytable==2.1.0\n",
            "progressbar2==3.38.0\n",
            "prometheus-client==0.11.0\n",
            "promise==2.3\n",
            "prompt-toolkit==1.0.18\n",
            "protobuf==3.12.4\n",
            "psutil==5.4.8\n",
            "psycopg2==2.7.6.1\n",
            "ptyprocess==0.7.0\n",
            "py==1.10.0\n",
            "pyarrow==3.0.0\n",
            "pyasn1==0.4.8\n",
            "pyasn1-modules==0.2.8\n",
            "pycocotools==2.0.2\n",
            "pycparser==2.20\n",
            "pyct==0.4.8\n",
            "pydata-google-auth==1.2.0\n",
            "pydot==1.3.0\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "pyemd==0.5.1\n",
            "pyerfa==2.0.0\n",
            "pyglet==1.5.0\n",
            "Pygments==2.6.1\n",
            "pygobject==3.26.1\n",
            "pymc3==3.11.2\n",
            "PyMeeus==0.5.11\n",
            "pymongo==3.11.4\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.5\n",
            "pyparsing==2.4.7\n",
            "pyrsistent==0.17.3\n",
            "pysndfile==1.3.8\n",
            "PySocks==1.7.1\n",
            "pystan==2.19.1.1\n",
            "pytest==3.6.4\n",
            "python-apt==0.0.0\n",
            "python-chess==0.23.11\n",
            "python-dateutil==2.8.1\n",
            "python-louvain==0.15\n",
            "python-slugify==5.0.2\n",
            "python-utils==2.5.6\n",
            "pytz==2018.9\n",
            "PyVirtualDisplay==2.2\n",
            "pyviz-comms==2.0.2\n",
            "PyWavelets==1.1.1\n",
            "PyYAML==3.13\n",
            "pyzmq==22.1.0\n",
            "qdldl==0.1.5.post0\n",
            "qtconsole==5.1.0\n",
            "QtPy==1.9.0\n",
            "regex==2019.12.20\n",
            "requests==2.23.0\n",
            "requests-oauthlib==1.3.0\n",
            "resampy==0.2.2\n",
            "retrying==1.3.3\n",
            "rpy2==3.4.5\n",
            "rsa==4.7.2\n",
            "scikit-image==0.16.2\n",
            "scikit-learn==0.22.2.post1\n",
            "scipy==1.4.1\n",
            "screen-resolution-extra==0.0.0\n",
            "scs==2.1.4\n",
            "seaborn==0.11.1\n",
            "semver==2.13.0\n",
            "Send2Trash==1.5.0\n",
            "setuptools-git==1.2\n",
            "Shapely==1.7.1\n",
            "simplegeneric==0.8.1\n",
            "six==1.15.0\n",
            "sklearn==0.0\n",
            "sklearn-pandas==1.8.0\n",
            "smart-open==5.1.0\n",
            "snowballstemmer==2.1.0\n",
            "sortedcontainers==2.4.0\n",
            "SoundFile==0.10.3.post1\n",
            "spacy==2.2.4\n",
            "Sphinx==1.8.5\n",
            "sphinxcontrib-serializinghtml==1.1.5\n",
            "sphinxcontrib-websupport==1.2.4\n",
            "SQLAlchemy==1.4.18\n",
            "sqlparse==0.4.1\n",
            "srsly==1.0.5\n",
            "statsmodels==0.10.2\n",
            "sympy==1.7.1\n",
            "tables==3.4.4\n",
            "tabulate==0.8.9\n",
            "tblib==1.7.0\n",
            "tensorboard==2.5.0\n",
            "tensorboard-data-server==0.6.1\n",
            "tensorboard-plugin-wit==1.8.0\n",
            "tensorflow==2.5.0\n",
            "tensorflow-datasets==4.0.1\n",
            "tensorflow-estimator==2.5.0\n",
            "tensorflow-gcs-config==2.5.0\n",
            "tensorflow-hub==0.12.0\n",
            "tensorflow-metadata==1.0.0\n",
            "tensorflow-probability==0.12.1\n",
            "termcolor==1.1.0\n",
            "terminado==0.10.1\n",
            "testpath==0.5.0\n",
            "text-unidecode==1.3\n",
            "textblob==0.15.3\n",
            "Theano-PyMC==1.1.2\n",
            "thinc==7.4.0\n",
            "tifffile==2021.6.14\n",
            "toml==0.10.2\n",
            "toolz==0.11.1\n",
            "torch==1.8.1+cu101\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.9.1\n",
            "torchvision==0.9.1+cu101\n",
            "tornado==5.1.1\n",
            "tqdm==4.41.1\n",
            "traitlets==5.0.5\n",
            "tweepy==3.10.0\n",
            "typeguard==2.7.1\n",
            "typing-extensions==3.7.4.3\n",
            "tzlocal==1.5.1\n",
            "uritemplate==3.0.1\n",
            "urllib3==1.24.3\n",
            "vega-datasets==0.9.0\n",
            "wasabi==0.8.2\n",
            "wcwidth==0.2.5\n",
            "webencodings==0.5.1\n",
            "Werkzeug==1.0.1\n",
            "widgetsnbextension==3.5.1\n",
            "wordcloud==1.5.0\n",
            "wrapt==1.12.1\n",
            "xarray==0.18.2\n",
            "xgboost==0.90\n",
            "xkit==0.0.0\n",
            "xlrd==1.1.0\n",
            "xlwt==1.3.0\n",
            "yellowbrick==0.9.1\n",
            "zict==2.0.0\n",
            "zipp==3.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrkVvTrvWZ5H"
      },
      "source": [
        "## 什麼是 Lunar Lander？\n",
        "\n",
        "“LunarLander-v2” 這個環境是在模擬登月小艇降落在月球表面時的情形。\n",
        "這個任務的目標是讓登月小艇「安全地」降落在兩個黃色旗幟間的平地上。\n",
        "> Landing pad is always at coordinates (0,0).\n",
        "> Coordinates are the first two numbers in state vector.\n",
        "\n",
        "![](https://gym.openai.com/assets/docs/aeloop-138c89d44114492fd02822303e6b4b07213010bb14ca5856d2d49d6b62d88e53.svg)\n",
        "\n",
        "所謂的「環境」其實同時包括了 agent 和 environment。\n",
        "我們利用 `step()` 這個函式讓 agent 行動，而後函式便會回傳 environment 給予的 observation/state（以下這兩個名詞代表同樣的意思）和 reward。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIbp82sljvAt"
      },
      "source": [
        "### Observation / State\n",
        "\n",
        "首先，我們可以看看 environment 回傳給 agent 的 observation 究竟是長什麼樣子的資料："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsXZra3N9R5T",
        "outputId": "80b31329-cde3-4f2e-e931-a460dad4d996"
      },
      "source": [
        "print(env.observation_space)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Box(-inf, inf, (8,), float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezdfoThbAQ49"
      },
      "source": [
        "`Box(8,)` 說明我們會拿到 8 維的向量作為 observation，其中包含：垂直及水平座標、速度、角度、加速度等等，這部分我們就不細說。\n",
        "\n",
        "### Action\n",
        "\n",
        "而在 agent 得到 observation 和 reward 以後，能夠採取的動作有："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1k4dIrBAaKi",
        "outputId": "9a024cc4-0529-47e2-893f-da93f50e6ce3"
      },
      "source": [
        "print(env.action_space)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Discrete(4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dejXT6PHBrPn"
      },
      "source": [
        "`Discrete(4)` 說明 agent 可以採取四種離散的行動：\n",
        "- 0 代表不採取任何行動\n",
        "- 2 代表主引擎向下噴射\n",
        "- 1, 3 則是向左右噴射\n",
        "\n",
        "接下來，我們嘗試讓 agent 與 environment 互動。\n",
        "在進行任何操作前，建議先呼叫 `reset()` 函式讓整個「環境」重置。\n",
        "而這個函式同時會回傳「環境」最初始的狀態。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi4OmrmZgnWA",
        "outputId": "005cfef1-7a38-48e1-c74f-1a67ed797d01"
      },
      "source": [
        "initial_state = env.reset()\n",
        "print(initial_state)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.00396109  1.4083536   0.40119505 -0.11407257 -0.00458307 -0.09087662\n",
            "  0.          0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBx0mEqqgxJ9"
      },
      "source": [
        "接著，我們試著從 agent 的四種行動空間中，隨機採取一個行動"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxkOEXRKgizt",
        "outputId": "021fcf48-1615-47c5-ba52-a694f8d645f0"
      },
      "source": [
        "random_action = env.action_space.sample()\n",
        "print(random_action)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mns-bO01g0-J"
      },
      "source": [
        "再利用 `step()` 函式讓 agent 根據我們隨機抽樣出來的 `random_action` 動作。\n",
        "而這個函式會回傳四項資訊：\n",
        "- observation / state\n",
        "- reward\n",
        "- 完成與否\n",
        "- 其餘資訊"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_WViSxGgIk9"
      },
      "source": [
        "observation, reward, done, info = env.step(random_action)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdieGq7NuBIm"
      },
      "source": [
        "第一項資訊 `observation` 即為 agent 採取行動之後，agent 對於環境的 observation 或者說環境的 state 為何。\n",
        "而第三項資訊 `done` 則是 `True` 或 `False` 的布林值，當登月小艇成功著陸或是不幸墜毀時，代表這個回合（episode）也就跟著結束了，此時 `step()` 函式便會回傳 `done = True`，而在那之前，`done` 則保持 `False`。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK7r126kuCNp",
        "outputId": "b52890f5-f36d-4faa-b4d2-4acaad72aefe"
      },
      "source": [
        "print(done)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKdS8vOihxhc"
      },
      "source": [
        "### Reward\n",
        "\n",
        "而「環境」給予的 reward 大致是這樣計算：\n",
        "- 小艇墜毀得到 -100 分\n",
        "- 小艇在黃旗幟之間成功著地則得 100~140 分\n",
        "- 噴射主引擎（向下噴火）每次 -0.3 分\n",
        "- 小艇最終完全靜止則再得 100 分\n",
        "- 小艇每隻腳碰觸地面 +10 分\n",
        "\n",
        "> Reward for moving from the top of the screen to landing pad and zero speed is about 100..140 points.\n",
        "> If lander moves away from landing pad it loses reward back.\n",
        "> Episode finishes if the lander crashes or comes to rest, receiving additional -100 or +100 points.\n",
        "> Each leg ground contact is +10.\n",
        "> Firing main engine is -0.3 points each frame.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxQNs77hi0_7",
        "outputId": "a28a71b5-8357-44f1-ebf7-b4e3fc2f17cb"
      },
      "source": [
        "print(reward) # after doing a random action (0), the immediate reward is stored in this "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.8588900517154912\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhqp6D-XgHpe"
      },
      "source": [
        "### Random Agent\n",
        "\n",
        "最後，在進入實做之前，我們就來看看這樣一個 random agent 能否成功登陸月球："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "Y3G0bxoccelv",
        "outputId": "90786e93-cb3e-47c2-ae0b-42198ec78964"
      },
      "source": [
        "\n",
        "env.reset()\n",
        "\n",
        "img = plt.imshow(env.render(mode='rgb_array'))\n",
        "\n",
        "done = False\n",
        "while not done:\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, done, _ = env.step(action)\n",
        "\n",
        "    img.set_data(env.render(mode='rgb_array'))\n",
        "    display.display(plt.gcf())\n",
        "    display.clear_output(wait=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5paWqo7tWL2"
      },
      "source": [
        "## Policy Gradient\n",
        "\n",
        "現在來搭建一個簡單的 policy network。\n",
        "我們預設模型的輸入是 8-dim 的 observation，輸出則是離散的四個動作之一："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8tdmeD-tZew"
      },
      "source": [
        "class PolicyGradientNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(8, 16)\n",
        "        self.fc2 = nn.Linear(16, 16)\n",
        "        self.fc3 = nn.Linear(16, 4)\n",
        "\n",
        "    def forward(self, state):\n",
        "        hid = torch.tanh(self.fc1(state))\n",
        "        hid = torch.tanh(self.fc2(hid))\n",
        "        return F.softmax(self.fc3(hid), dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynbqJrhIFTC3"
      },
      "source": [
        "再來，搭建一個簡單的 agent，並搭配上方的 policy network 來採取行動。\n",
        "這個 agent 能做到以下幾件事：\n",
        "- `learn()`：從記下來的 log probabilities 及 rewards 來更新 policy network。\n",
        "- `sample()`：從 environment 得到 observation 之後，利用 policy network 得出應該採取的行動。\n",
        "而此函式除了回傳抽樣出來的 action，也會回傳此次抽樣的 log probabilities。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZo-IxJx286z"
      },
      "source": [
        "\n",
        "class PolicyGradientAgent():\n",
        "    \n",
        "    def __init__(self, network):\n",
        "        self.network = network\n",
        "        self.optimizer = optim.SGD(self.network.parameters(), lr=0.001)\n",
        "         \n",
        "    def forward(self, state):\n",
        "        return self.network(state)\n",
        "    def learn(self, log_probs, rewards):\n",
        "        loss = (-log_probs * rewards).sum() # You don't need to revise this to pass simple baseline (but you can)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        \n",
        "    def sample(self, state):\n",
        "        action_prob = self.network(torch.FloatTensor(state))\n",
        "        action_dist = Categorical(action_prob)\n",
        "        action = action_dist.sample()\n",
        "        log_prob = action_dist.log_prob(action)\n",
        "        return action.item(), log_prob\n",
        "\n",
        "    def save(self, PATH): # You should not revise this\n",
        "        Agent_Dict = {\n",
        "            \"network\" : self.network.state_dict(),\n",
        "            \"optimizer\" : self.optimizer.state_dict()\n",
        "        }\n",
        "        torch.save(Agent_Dict, PATH)\n",
        "\n",
        "    def load(self, PATH): # You should not revise this\n",
        "        checkpoint = torch.load(PATH)\n",
        "        self.network.load_state_dict(checkpoint[\"network\"])\n",
        "        #如果要儲存過程或是中斷訓練後想繼續可以用喔 ^_^\n",
        "        self.optimizer.load_state_dict(checkpoint[\"optimizer\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehPlnTKyRZf9"
      },
      "source": [
        "最後，建立一個 network 和 agent，就可以開始進行訓練了。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfJIvML-RYjL"
      },
      "source": [
        "network = PolicyGradientNetwork()\n",
        "agent = PolicyGradientAgent(network)\n",
        "#agent = PolicyGradientAgent()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouv23glgf5Qt"
      },
      "source": [
        "## 訓練 Agent\n",
        "\n",
        "現在我們開始訓練 agent。\n",
        "透過讓 agent 和 environment 互動，我們記住每一組對應的 log probabilities 及 reward，並在成功登陸或者不幸墜毀後，回放這些「記憶」來訓練 policy network。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg5rxBBaf38_"
      },
      "source": [
        "agent.network.train()  # 訓練前，先確保 network 處在 training 模式\n",
        "EPISODE_PER_BATCH = 5  # 每蒐集 5 個 episodes 更新一次 agent\n",
        "NUM_BATCH = 700        # 總共更新 400 次\n",
        "\n",
        "avg_total_rewards, avg_final_rewards = [], []\n",
        "\n",
        "prg_bar = tqdm(range(NUM_BATCH))\n",
        "best_reward=0\n",
        "best_log_probs, best_rewards = [], []\n",
        "for batch in prg_bar:\n",
        "\n",
        "    log_probs, rewards = [], []\n",
        "    total_rewards, final_rewards = [], []\n",
        "\n",
        "    # 蒐集訓練資料\n",
        "    for episode in range(EPISODE_PER_BATCH):\n",
        "        \n",
        "        state = env.reset()\n",
        "        total_reward, total_step = 0, 0\n",
        "        seq_rewards = []\n",
        "        while True:\n",
        "\n",
        "            action, log_prob = agent.sample(state) # at , log(at|st)\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "            log_probs.append(log_prob) # [log(a1|s1), log(a2|s2), ...., log(at|st)]\n",
        "            seq_rewards.append(reward)\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "            total_step += 1\n",
        "\n",
        "            # i=0\n",
        "            # print(f\"Length of seq_rewards:  \",len(seq_rewards))\n",
        "            # while total_step <len(seq_rewards):\n",
        "            #     reward=reward*(0.99**i)\n",
        "            #     i+=1\n",
        "                \n",
        "            # rewards.append(reward) #改這裡\n",
        "            \n",
        "            # ! 重要 ！\n",
        "            # 現在的reward 的implementation 為每個時刻的瞬時reward, 給定action_list : a1, a2, a3 ......\n",
        "            #                                                       reward :     r1, r2 ,r3 ......\n",
        "            # medium：將reward調整成accumulative decaying reward, 給定action_list : a1,                         a2,                           a3 ......\n",
        "            #                                                       reward :     r1+0.99*r2+0.99^2*r3+......, r2+0.99*r3+0.99^2*r4+...... ,r3+0.99*r4+0.99^2*r5+ ......\n",
        "            # boss : implement DQN\n",
        "            if done:\n",
        "                final_rewards.append(reward)\n",
        "                total_rewards.append(total_reward)\n",
        "\n",
        "                for i in range (len(seq_rewards)):\n",
        "                    j=i\n",
        "                    reward=0\n",
        "                    while j <len(seq_rewards):\n",
        "                        reward+=seq_rewards[j]*(0.99**(j-i))\n",
        "                        j+=1\n",
        "                    rewards.append(reward)\n",
        "\n",
        "                break\n",
        "\n",
        "    # print(f\"rewards looks like \", np.shape(rewards))  \n",
        "    # print(f\"log_probs looks like \", np.shape(log_probs))     \n",
        "    # 紀錄訓練過程\n",
        "    avg_total_reward = sum(total_rewards) / len(total_rewards)\n",
        "    avg_final_reward = sum(final_rewards) / len(final_rewards)\n",
        "    avg_total_rewards.append(avg_total_reward)\n",
        "    avg_final_rewards.append(avg_final_reward)\n",
        "    prg_bar.set_description(f\"Total: {avg_total_reward: 4.1f}, Final: {avg_final_reward: 4.1f}\")\n",
        "    \n",
        "    # 更新網路\n",
        "    # rewards = np.concatenate(rewards, axis=0)\n",
        "    rewards = (rewards - np.mean(rewards)) / (np.std(rewards) + 1e-9)  # 將 reward 正規標準化\n",
        "    agent.learn(torch.stack(log_probs), torch.from_numpy(rewards))\n",
        "    # print(\"logs prob looks like \", torch.stack(log_probs).size())\n",
        "    # print(\"torch.from_numpy(rewards) looks like \", torch.from_numpy(rewards).size())\n",
        "\n",
        "    # if avg_total_reward>best_reward:\n",
        "    #     best_log_probs=log_probs\n",
        "    #     best_rewards=rewards\n",
        "    #     best_reward=avg_total_reward\n",
        "    #     print('Best reward saved!')\n",
        "    if avg_total_reward>235:\n",
        "      print(f\"Average total reward: \",avg_total_reward)\n",
        "      break\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNb_tuFYhKVK"
      },
      "source": [
        "### 訓練結果\n",
        "\n",
        "訓練過程中，我們持續記下了 `avg_total_reward`，這個數值代表的是：每次更新 policy network 前，我們讓 agent 玩數個回合（episodes），而這些回合的平均 total rewards 為何。\n",
        "理論上，若是 agent 一直在進步，則所得到的 `avg_total_reward` 也會持續上升，直至 250 上下。\n",
        "若將其畫出來則結果如下："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZYOI8H10SHN"
      },
      "source": [
        "end = time.time()\n",
        "plt.plot(avg_total_rewards)\n",
        "plt.title(\"Total Rewards\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV5jj4dThz0Y"
      },
      "source": [
        "另外，`avg_final_reward` 代表的是多個回合的平均 final rewards，而 final reward 即是 agent 在單一回合中拿到的最後一個 reward。\n",
        "如果同學們還記得環境給予登月小艇 reward 的方式，便會知道，不論**回合的最後**小艇是不幸墜毀、飛出畫面、或是靜止在地面上，都會受到額外地獎勵或處罰。\n",
        "也因此，final reward 可被用來觀察 agent 的「著地」是否順利等資訊。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txDZ5vlGWz5w"
      },
      "source": [
        "plt.plot(avg_final_rewards)\n",
        "plt.title(\"Final Rewards\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyT7tNwkVdS-"
      },
      "source": [
        "訓練時間\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_t-JsKxUViFy",
        "outputId": "edc47512-034f-4985-cb1a-fbe8bfb40726"
      },
      "source": [
        "print(f\"total time is {end-start} sec\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total time is 4771.225242614746 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2HaGRVEYGQS"
      },
      "source": [
        "## 測試"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "5yFuUKKRYH73",
        "outputId": "8d799178-052c-4319-9f2c-a4919591323f"
      },
      "source": [
        "fix(env, seed)\n",
        "agent.network.eval()  # 測試前先將 network 切換為 evaluation 模式\n",
        "NUM_OF_TEST = 5 # Do not revise it !!!!!\n",
        "test_total_reward = []\n",
        "action_list = []\n",
        "for i in range(NUM_OF_TEST):\n",
        "  actions = []\n",
        "  state = env.reset()\n",
        "\n",
        "  img = plt.imshow(env.render(mode='rgb_array'))\n",
        "\n",
        "  total_reward = 0\n",
        "\n",
        "  done = False\n",
        "  while not done:\n",
        "      action, _ = agent.sample(state)\n",
        "      actions.append(action)\n",
        "      state, reward, done, _ = env.step(action)\n",
        "\n",
        "      total_reward += reward\n",
        "\n",
        "      # img.set_data(env.render(mode='rgb_array'))\n",
        "      # display.display(plt.gcf())\n",
        "      # display.clear_output(wait=True)\n",
        "  print(total_reward)\n",
        "  test_total_reward.append(total_reward)\n",
        "\n",
        "  action_list.append(actions) #儲存你測試的結果\n",
        "  print(\"length of actions is \", len(actions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/__init__.py:422: UserWarning: torch.set_deterministic is deprecated and will be removed in a future release. Please use torch.use_deterministic_algorithms instead\n",
            "  \"torch.set_deterministic is deprecated and will be removed in a future \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "228.35937866950087\n",
            "length of actions is  308\n",
            "211.9813649388971\n",
            "length of actions is  324\n",
            "97.23389365394624\n",
            "length of actions is  760\n",
            "278.90450347233553\n",
            "length of actions is  269\n",
            "205.5978897442302\n",
            "length of actions is  501\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aex7mcKr0J01",
        "outputId": "25c501d0-fbc8-42ae-aae2-0eaa8ce84ea1"
      },
      "source": [
        "print(f\"Your final reward is : %.2f\"%np.mean(test_total_reward))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your final reward is : 204.42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leyebGYRpqsF"
      },
      "source": [
        "Action list 的長相"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGAH4YWDpp4u",
        "outputId": "890586b8-8ee2-4d3e-8a70-87bd4a3b699d"
      },
      "source": [
        "print(\"Action list looks like \", action_list)\n",
        "print(\"Action list's shape looks like \", np.shape(action_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Action list looks like  [[1, 1, 1, 1, 1, 1, 1, 3, 1, 0, 0, 1, 2, 3, 3, 0, 2, 2, 1, 3, 0, 2, 2, 3, 3, 2, 3, 2, 2, 2, 2, 3, 3, 2, 2, 3, 2, 3, 3, 2, 2, 2, 2, 3, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 3, 3, 3, 1, 2, 2, 2, 2, 2, 3, 3, 2, 2, 1, 3, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 1, 2, 1, 2, 1, 1, 2, 2, 3, 1, 3, 1, 2, 2, 2, 2, 1, 3, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 3, 2, 2, 3, 2, 2, 2, 1, 1, 2, 3, 2, 1, 2, 2, 2, 2, 0, 3, 2, 2, 2, 3, 2, 2, 3, 2, 3, 2, 1, 2, 2, 1, 1, 1, 2, 0, 1, 2, 2, 2, 0, 3, 2, 3, 3, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2, 3, 1, 1, 2, 2, 3, 2, 1, 2, 2, 3, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 2, 2, 1, 0, 2, 3, 2, 3, 2, 2, 2, 2, 3, 3, 3, 2, 1, 2, 2, 2, 3, 3, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 0, 2, 2, 2, 2, 3, 2, 0, 0, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 3, 1, 3, 1, 1, 3, 3, 3, 0, 3, 0, 0, 1, 3, 3, 3, 3, 2, 1, 1, 0, 2, 2, 2, 2, 3, 3, 2, 3, 3, 2, 2, 3, 2, 2, 2, 3, 2, 3, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 3, 2, 2, 2, 2, 2, 1, 2, 3, 3, 1, 2, 2, 1, 0, 2, 2, 3, 1, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 1, 2, 3, 3, 2, 0, 2, 2, 1, 2, 1, 1, 2, 2, 3, 0, 2, 3, 3, 3, 2, 3, 1, 2, 2, 2, 2, 2, 2, 3, 3, 1, 1, 2, 2, 2, 2, 2, 3, 1, 2, 1, 2, 3, 2, 2, 3, 3, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 3, 3, 2, 2, 2, 1, 2, 1, 2, 0, 2, 2, 3, 0, 2, 0, 3, 2, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 0, 2, 2, 3, 2, 1, 1, 1, 2, 2, 1, 0, 1, 1, 3, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 3, 1, 1, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 1, 2, 3, 2, 3, 2, 3, 2, 2, 2, 3, 3, 2, 2, 2, 3, 2, 3, 0, 2, 2, 2, 2, 3, 2, 2, 2, 1, 2, 0, 2, 3, 2, 2, 2, 3, 1, 2, 3, 1, 2, 2, 1, 2, 3, 3, 1, 2, 1, 2, 2, 2, 2, 3, 0, 2, 2, 1, 2, 3, 2, 1, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 1, 0, 3, 2, 1, 2, 3, 2, 2, 2, 2, 2, 2, 1, 3, 1, 2, 2, 3, 3, 2, 2, 2, 2, 2, 0, 2, 1, 2, 1, 1, 2, 1, 2, 0, 2, 2, 1, 1, 2, 2, 2, 0, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 0, 1, 3, 3, 2, 1, 1, 3, 3, 2, 2, 3, 2, 0, 0, 3, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 0, 2, 1, 2, 2, 3, 1, 2, 0, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 0, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 0, 2, 3, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 3, 3, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 3, 0, 3, 3, 1, 1, 3, 0, 0, 3, 1, 3, 1, 3, 0, 3, 1, 3, 0, 1, 0, 0, 0, 0, 3, 0, 0, 1, 3, 1, 1, 0, 1, 1, 1, 3, 1, 1, 3, 0, 0, 1, 0, 0, 1, 3, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 3, 1, 1, 1, 3, 0, 1, 3, 1, 1, 1, 1, 1, 0, 3, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 3, 1, 0, 3, 0, 3, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 3, 1, 1, 1, 1, 0, 3, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 3, 0, 1, 3, 1, 0, 1, 1, 3, 3, 0, 0, 3, 1, 0, 0, 0, 1, 0, 1, 1, 3, 0, 0, 0, 1, 3, 0, 1, 0, 3, 0, 1, 1, 1, 3, 1, 3, 1, 1, 0, 0, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 1, 2, 1, 1, 1, 3, 1, 1, 3, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 2, 0, 0, 1, 1, 3, 3, 1, 1, 2, 3, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 0, 1, 0, 1, 0, 0, 3, 1, 2, 1, 1, 1, 0, 1, 3, 1, 3, 3, 0, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 2, 3, 3, 2, 3, 2, 3, 3, 2, 3, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 3, 2, 2, 2, 2, 2, 3, 3, 3, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 3, 2, 1, 2, 3, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 3, 2, 2, 1, 2, 2, 2, 3, 3, 2, 2, 1, 2, 2, 3, 2, 2, 2, 2, 2, 1, 1, 2, 2, 3, 2, 1, 2, 2, 1, 2, 3, 1, 2, 2, 0, 3, 0, 2, 2, 2, 3, 2, 2, 1, 2, 0, 0, 2, 1, 2, 3, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 0, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 1, 1, 0, 1, 1, 3, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 0, 1, 2, 2, 1, 2, 0, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 3, 2, 1, 0, 2, 3, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 0, 1, 3, 3, 2, 0, 2, 0, 2, 2, 3, 1, 2, 2, 2, 2, 3, 1, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 3, 1, 3, 2, 2, 2, 3, 2, 0, 2, 2, 1, 2, 2, 3, 1, 2, 3, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 3, 1, 1, 0, 2, 1, 3, 2, 2, 3, 0, 0, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 3, 2, 2, 2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 2, 0, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 3, 1, 2, 2, 1, 2, 3, 1, 2, 2, 1, 2, 1, 2, 3, 0, 2, 2, 3, 2, 2, 2, 2, 0, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 3, 2, 2, 2, 3, 2, 2, 3, 0, 2, 2, 1, 2, 3, 2, 2, 1, 1, 2, 2, 1, 2, 3, 3, 2, 3, 3, 2, 1, 1, 2, 2, 2, 2, 3, 1, 3, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 1, 2, 2, 3, 2, 2, 2, 1, 2, 1, 3, 0, 2, 1, 2, 1, 3, 0, 2, 3, 2, 2, 0, 1, 3, 2, 2, 2, 2, 2, 1, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 0, 3, 3, 0, 1, 3, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 3, 1, 3, 0, 1, 1, 3, 3, 2, 0, 1, 1, 2, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]\n",
            "Action list's shape looks like  (5,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7sokqEUtrFY"
      },
      "source": [
        "Action 的分布\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHdAItjj1nxw",
        "outputId": "752c810f-6c76-458b-c2d9-e63e34f95724"
      },
      "source": [
        "distribution = {}\n",
        "for actions in action_list:\n",
        "  for action in actions:\n",
        "    if action not in distribution.keys():\n",
        "      distribution[action] = 1\n",
        "    else:\n",
        "      distribution[action] += 1\n",
        "print(distribution)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 553, 3: 703, 0: 176, 2: 730}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ricE0schY75M"
      },
      "source": [
        "儲存 Model Testing的結果\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZsMkGmIY42b",
        "outputId": "8dde3720-98a9-4917-bffd-e3d8a7d9d4ad"
      },
      "source": [
        "PATH = \"Action_List_test5.npy\" # 可以改成你想取的名字或路徑\n",
        "np.save(PATH ,np.array(action_list)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asK7WfbkaLjt"
      },
      "source": [
        "### 你要交到JudgeBoi的檔案94這個\n",
        "儲存結果到本地端 (就是你的電腦裡拉 = = )\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "c-CqyhHzaWAL",
        "outputId": "884597a2-30da-48ec-e6d6-2e8d011942c0"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_86496abe-befd-4a06-9710-ac447e44b537\", \"Action_List_test5.npy\", 4631)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seT4NUmWmAZ1"
      },
      "source": [
        "# Server 測試\n",
        "到時候下面會是我們Server上測試的環境，可以給大家看一下自己的表現如何"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "U69c-YTxaw6b",
        "outputId": "14d44abc-706f-4186-82f6-92f4f2dd7552"
      },
      "source": [
        "# PATH=\"/content/Action_List_test4.npy\"\n",
        "action_list = np.load(PATH,allow_pickle=True) #到時候你上傳的檔案\n",
        "seed = 543 #到時候測試的seed 請不要更改\n",
        "fix(env, seed)\n",
        "\n",
        "agent.network.eval()  # 測試前先將 network 切換為 evaluation 模式\n",
        "test_total_reward = []\n",
        "\n",
        "import cv2\n",
        "import glob\n",
        "count=0\n",
        "img_array = []\n",
        "for actions in action_list:\n",
        "  state = env.reset()\n",
        "  img = plt.imshow(env.render(mode='rgb_array'))\n",
        "\n",
        "  total_reward = 0\n",
        "\n",
        "  done = False\n",
        "  # while not done:\n",
        "  done_count = 0\n",
        "  count+=1\n",
        "\n",
        "  for action in actions:\n",
        "      # action, _ = agent1.sample(state)\n",
        "      state, reward, done, _ = env.step(action)\n",
        "      done_count += 1\n",
        "      total_reward += reward\n",
        "      if done:\n",
        "        break\n",
        "      # img.set_data(env.render(mode='rgb_array'))\n",
        "      # display.display(plt.gcf())\n",
        "      # display.clear_output(wait=True)\n",
        "      if count==5:\n",
        "          img_array.append(env.render(mode='rgb_array'))\n",
        "\n",
        "  print(f\"Your reward is : %.2f\"%total_reward)\n",
        "  test_total_reward.append(total_reward)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/__init__.py:422: UserWarning: torch.set_deterministic is deprecated and will be removed in a future release. Please use torch.use_deterministic_algorithms instead\n",
            "  \"torch.set_deterministic is deprecated and will be removed in a future \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Your reward is : 249.22\n",
            "Your reward is : 243.67\n",
            "Your reward is : 225.74\n",
            "Your reward is : 261.89\n",
            "Your reward is : 282.73\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAcSElEQVR4nO3de3RU9d3v8fc3FwgRYkAgDRcRy60EEWxQ48M6ghwVPa6jthWttdJWC211Lbpqe9TnLH3sOauy7OkDlkPBIligF9HaqiwfHtF6WeqxouEiF5E2ikoihFuRIBKY5Hv+mE06csl1hslv5vNaa6/Z+7f3zP7+JpNPdn6zZ7a5OyIiEo6cdBcgIiJto+AWEQmMgltEJDAKbhGRwCi4RUQCo+AWEQlMyoLbzCab2RYzqzKzu1K1HxGRbGOpOI/bzHKBvwGXAtXAW8DX3f2dpO9MRCTLpOqI+3ygyt3fd/fDwDLg6hTtS0Qkq+Sl6HH7A9sSlquBC062sZnp45uSVDk5eRT1KKFbfi9ijfV8emgX9fUH6NE93tZR9bFPqPt0J+6N9DitLwX5xRyKfULdgVpisfok9EAE3N1O1J6q4G6RmU0DpqVr/5LZRo36b1SUTaOo6wDWVz/G/3vjYXr0KGHSxXcwqu91mHXsn82/73mWV978v9TUrGf4ly7h/KG3kmO5vFm1kNdffyRJvRA5sVQNldQAAxOWB0RtTdx9gbuXu3t5imqQLNWjR18GDRjHGYVD2fnpRqq2vsKBA7tSsq/Gxga2bn2D7fvXUpjfhwF9zqOkZHhK9iVyVKqC+y1gqJkNNrMuwA3A8hTtS+RzBg++kP7F5xFrPETN3jVs27Ympfurrd3Cmo2PUbO/kv6nj2PEsP9KQUFRSvcp2S0lQyXuHjOz24GVQC7wiLtvSsW+RBIVFX2BQf3H0bPgbKr3v8X7W1/n8OGDADQ2xjh05BPe/8dL2AlHDlvv4JHdn1uuqdnAx2etpe/AMob0u4Sdg//G5s1/AfT2jSRfysa43X0FsCJVjy9yIoMGlfOF00fT4Ef4+B9r+eij1U3r9u/fQeXqRyks7JmUfe3b98/Rv0OH9rP1w78y4IwvU9pjLGefdRFbt67i0KH9SdmXSKK0vTkpkgrujew5WMWuui2sW/cksdjhz62vrd2Ssn3X1Gyg5qw1dMntQWGXMygu7s+OHQpuSb6UfACnzUXodEBJkpycPE4/vZTc3Hx2737/lO9/2LCJ9O59Nh9++BY1NRvQUIl0xMlOB1RwiyRRTk4uubn5HDlyKN2lSAZQcIuIBOZkwa1vBxQRCYyCW0QkMApuEZHAKLhFRAKj4BYRCYyCW0QkMApuEZHAKLhFRAKj4BYRCYyCW0QkMApuEZHAKLhFRAKj4BYRCYyCW0QkMB26Ao6ZfQDUAQ1AzN3LzawX8BhwFvABMMXd/9GxMkVE5KhkHHFPdPcx7l4eLd8FvODuQ4EXomUREUmSVAyVXA0sieaXANekYB8iIlmro8HtwHNmttrMpkVtJe6+PZrfAZR0cB8iIpKgo1d5H+/uNWbWF3jezN5NXOnufrLLkkVBP+1E60RE5OSSds1JM7sPOAB8F5jg7tvNrBR42d2Ht3BfXXNSROQYSb/mpJmdZmY9js4DlwEbgeXA1GizqcDT7d2HiIgcr91H3GZ2NvBktJgH/MHdf2ZmZwCPA2cCHxI/HXBvC4+lI24RkWOc7Ig7aUMlHaHgFhE5XtKHSkREJD0U3CIigVFwi4gERsEtIhIYBbeISGAU3CIigVFwi4gERsEtIhIYBbeISGAU3CIigVFwi4gERsEtIhIYBbeISGAU3CIigVFwi4gERsEtIhIYBbeISGAU3CIigVFwi4gEpsXgNrNHzGynmW1MaOtlZs+b2d+j255Ru5nZHDOrMrP1ZnZeKosXEclGrTniXgxMPqbtLuAFdx8KvBAtA1wBDI2macD85JQpIiJHtRjc7v4KsPeY5quBJdH8EuCahPalHvcGUGxmpckqVkRE2j/GXeLu26P5HUBJNN8f2JawXXXUdhwzm2ZmlWZW2c4aRESyUl5HH8Dd3cy8HfdbACwAaM/9RUSyVXuPuGuPDoFEtzuj9hpgYMJ2A6I2ERFJkvYG93JgajQ/FXg6of3m6OySC4FPEoZUREQkCcy9+VEKM3sUmAD0BmqBfwOeAh4HzgQ+BKa4+14zM2Au8bNQDgLfdvcWx7A1VCIicjx3txO1txjcp4KCW0TkeCcLbn1yUkQkMApuEZHAKLhFRAKj4BYRCYyCW0QkMApuEZHAKLhFRAKj4BYRCYyCW0QkMApuEZHAKLhFRAKj4BYRCYyCW0QkMApuEZHAKLhFRAKj4BYRCYyCW0QkMApuEZHAtBjcZvaIme00s40JbfeZWY2ZrYumKxPW3W1mVWa2xcwuT1XhIiLZqjUXC/4vwAFgqbuPitruAw64+y+O2XYk8ChwPtAP+AswzN0bWtiHrjkpInKMdl9z0t1fAfa2cj9XA8vcvd7dtwJVxENcRESSpCNj3Leb2fpoKKVn1NYf2JawTXXUdhwzm2ZmlWZW2YEaRESyTnuDez7wRWAMsB3497Y+gLsvcPdydy9vZw0iIlmpXcHt7rXu3uDujcDD/HM4pAYYmLDpgKhNRESSpF3BbWalCYvXAkfPOFkO3GBmXc1sMDAUeLNjJYqISKK8ljYws0eBCUBvM6sG/g2YYGZjAAc+AKYDuPsmM3sceAeIAbe1dEaJiIi0TYunA56SInQ6oIjIcdp9OqCIiHQuCm4RkcAouEVEAqPgFhEJjIJbRCQwCm4RkcAouEVEAqPgFhEJjIJbRCQwCm4RkcAouEVEAqPgFhEJjIJbRCQwCm4RkcAouEVEAqPgFhEJjIJbRCQwCm4RkcC0GNxmNtDMXjKzd8xsk5nNiNp7mdnzZvb36LZn1G5mNsfMqsxsvZmdl+pOiIhkk9YccceAO9x9JHAhcJuZjQTuAl5w96HAC9EywBXEr+4+FJgGzE961SIiWazF4Hb37e6+JpqvAzYD/YGrgSXRZkuAa6L5q4GlHvcGUGxmpUmvXEQkS7VpjNvMzgLGAquAEnffHq3aAZRE8/2BbQl3q47ajn2saWZWaWaVbaxZRCSrtTq4zaw78Cfgh+6+P3Gduzvgbdmxuy9w93J3L2/L/UREsl2rgtvM8omH9u/d/c9Rc+3RIZDodmfUXgMMTLj7gKhNRESSoDVnlRiwCNjs7rMSVi0HpkbzU4GnE9pvjs4uuRD4JGFIRUREOsjioxzNbGA2HngV2AA0Rs3/Snyc+3HgTOBDYIq7742Cfi4wGTgIfNvdmx3HNrM2DbOIiGQDd7cTtbcY3KeCgltE5HgnC259clJEJDAKbhGRwCi4RUQCo+AWEQmMgltEJDAKbhGRwCi4RUQCo+AWEQmMgltEJDAKbhGRwCi4RUQCo+AWEQmMgltEJDAKbhGRwCi4RUQCo+AWEQmMgltEJDAKbhGRwLTmYsEDzewlM3vHzDaZ2Yyo/T4zqzGzddF0ZcJ97jazKjPbYmaXp7IDIiLZpjUXCy4FSt19jZn1AFYD1wBTgAPu/otjth8JPAqcD/QD/gIMc/eGZvaha06KiByj3decdPft7r4mmq8DNgP9m7nL1cAyd693961AFfEQFxGRJGjTGLeZnQWMBVZFTbeb2Xoze8TMekZt/YFtCXerpvmgFwHg/vun88ADMGoUjBwJ/fqlu6JTb8KECSxePJwrr4SyMhgxAnJz012VdDZ5rd3QzLoDfwJ+6O77zWw+8L8Bj27/HfhOGx5vGjCtbeVKJjvnnLMpLYVLLokvb98O77wTn3/2WaiqAnfYsQMaTjrwFrY+ffpw/vkHKCuLL8di8PrrcOQIVFfDU0/F2z/5BOrq0lenpFergtvM8omH9u/d/c8A7l6bsP5h4JlosQYYmHD3AVHb57j7AmBBdH+NcUsTi0b1+vX751H3xInx0G5ogJUr4bPP4sH+u9+lr85UOvoc5OfDxRfH593hppvi8xs3wpYt8fmlS6G29vjHkMzVmrNKDFgEbHb3WQntpQmbXQtsjOaXAzeYWVczGwwMBd5MXsmSjRob46Edi8HBg/Dpp/HwziZH/3A1NMChQ/Hn4NNP48+NZJfWHHH/C/BNYIOZrYva/hX4upmNIT5U8gEwHcDdN5nZ48A7QAy4rbkzSkQSuccniA8NrItecStXwvvvx9ft3Zv5YXX0eYjF4MUX4fBhqKmB5cvj6w8cyL4/XPJPLQa3u78GnOiUlBXN3OdnwM86UJdkoQMH4D/+Iz780dgYH8PdtSvdVZ1669bBww/Dhx/Gn4ePPsr8P1TSNq1+c1Ik1T76CO67L91VpN+sWVBZme4qpDPTR95FRAKj4BYRCYyCW0QkMApuaWJ2wq9FEJFORsEtjBgxgpkzZ/K73/2OCy64IN3liEgLdFZJFhsxYgTTp0/nq1/9KgMHxj/sesUVV7By5Up+/vOfs27dOlr69kgROfV0xJ2FBg8ezJw5c3j55ZeZMWNGU2gD9OzZk+uvv57XXnuNP/zhD4wePZq8PP19F+lMFNxZoqioiIEDBzJ79mxWr17N7bffTklJyQnHtc2MwsJCrr/+et566y1+85vf8KUvfSkNVYvIiehQKsN17dqVr33ta9x2222cc845nHbaaa1+E9LM6NKlC9/4xjc477zz+OUvf8nSpUs5dOhQiqsWkeboiDtD5ebmMmXKFF599VUWLlxIRUUF3bt3b9eZI2bGyJEjmTt3LqtXr+Zb3/oWBQUFKahaRFpDwZ1hCgoK+MpXvsIbb7zBb3/7W8aNG5e0kM3Pz2fkyJEsXLiQyspKvvnNb1JUVJSUxxaR1tNQSYYoKipi0qRJ3HnnnYwbN46cnNT9Tc7NzaWsrIwlS5awbt06Zs+ezYoVK9izZ0/K9impd/rppzNy5EgAjhw5wtq1a2nI1CtWBE7BHbji4mImTZrEjBkzGD9+/Cn9EI2ZMXbsWJYsWUJlZSW//vWvWb58Obuy8Sv9AtWnTx/69OnDj3/8Y4YNG8ZFF10ExIN7xYoVzJw5k48//pjq6uo0Vyqf4+5pn4h/p7emNkxFRUV+4403+iuvvOKxWMw7g4aGBl+zZo1///vf9+Li4jb36YEHHkj785ru6brrrvPy8vKUPX5BQYGXlJT4T37yE58/f76vXbvWY7GYNzY2HvfzbGxs9Fgs5lu3bvV77rnHe/funfbnJ9smP1lmnmzFqZzS/eSEMuXm5vrw4cP93nvv9b/+9a9eX1+fxNhNnsOHD/uGDRt8+vTp3q1bt1b3T8Gd/ODOycnxwsJCv+KKK/zee+/1ZcuWeV1dnR85cqRNP9NYLObbtm3zO++804uLiz263KCmFE+u4A53MjMvKyvzWbNm+e7du9sYo+lTX1/vmzZt8qlTp3pBQUGL/VRwJye4c3JyfMiQIX7rrbf6Pffc4zU1NV5XV5eUn2lDQ4Nv27bNf/SjH/nkyZMV4CmeXMEd5nTuuef63Llzffv27Un5xUuHWCzmGzdu9IkTJzbbVwV3x4J77NixPmXKFK+srPTq6uqU/1zr6up85cqVPmnSJAV4iiZvb3ADBcQv9vs2sAn4adQ+GFgFVAGPAV2i9q7RclW0/qxW7CPtT1Bnm8455xxfsGCB79ixI+W/gKdKbW2tL1y40EePHn3CPiu42xbcpaWlftFFF/myZcv81Vdf9dra2rT8XA8ePOgrV670iy++2Lt06ZL25zCTJu9AcBvQPZrPJx7GFwKPAzdE7Q8B34/mfwA8FM3fADzWin2k/QnqDJOZ+bBhw/zhhx/2PXv2nPANo9A1Njb63r17fdGiRT58+HDPyclp6r+Cu/ngLiws9OHDh/s999zjTz75pK9fv75TvUZisZg/++yzPnPmTB80aFDan8tMmDwZQyVAIbAGuADYDeRF7RXAymh+JVARzedF21kLj5v2JyhdU69evbykpMSHDBniDz30kNfV1XWqX8ZUaWxs9AMHDviCBQt82LBhnpeXp+Dm88Gdk5PjJSUl3q9fP585c6YvX77cY7GYNzQ0pPvH16zGxkb/+OOP/f777/eSkhINo3Rg8pNkpnk8OJtlZrnAamAI8Cvg/wBvuPuQaP1A4D/dfZSZbQQmu3t1tO494AJ3393M47dcRMC6devWdH715ZdfzujRo5vW3XjjjfTv3x8z+9x22cLdOXjwIIsXL2bLli088sgjtOY1manKysrYt28fFRUVjB49mltvvZW8vDy6deuW0g9VpUJjYyN79uxh/vz5zJs3j3379lFfX5/usoLi7icMhFYFd9PGZsXAk8A9wOKOBLeZTQOmRYtfbmN/OhUz+1zgXnrppQwaNKhp3e23307v3r2B+CccCwsL01JnZ7d3714OHz6c7jI6hZ49e9K1a9d0l5EU7s6uXbt49913mT17NsuXL6exsTHdZQUhKcENYGb3Ap8BdwJfcPeYmVUA97n75Wa2Mpr/q5nlATuAPt7MjkI84h4/fjxnnHEGAJMmTeLSSy9tWte/f3969OiRrtJEOq3PPvuM1atXM3PmTJ577jlisVi6S+rU2h3cZtYHOOLu+8ysG/Ac8AAwFfiTuy8zs4eA9e4+z8xuA85x9++Z2Q3AV9x9Sgv76HTB3bdvX4YOHdq0fO2111JRUdG0PGrUKH3Bkkg7HTlyhFWrVnH//ffzwQcfsHnz5nSX1Cl1JLhHA0uAXOLfJvi4u/8vMzsbWAb0AtYCN7l7vZkVAL8FxgJ7iZ958n5z+xgyZIjPmjWr2Tqqq6uZO3dus9t01E033cSoUaMAOPPMMxkzZkxK9ycisGPHDp544gkefPBB3nvvvXSX06kkbagkFcrLy72ysrLZbdw95eNiOTk5WffmoEhn4O7s27ePpUuXMmvWLKqrqzUOTgYEt4hkPndn//79LFy4kLfffps//vGPWX3FJQW3iASlvr6eDRs28Itf/IInnngiK78b/GTBHdaJoSKSNbp27Up5eTlLly5l1apVTJkyRe87RXTELSLBqK2t5ZlnnmHOnDmsX78+3eWknI64RSR4JSUl3HLLLbz00kssXLiQsrKypg+3ZRMFt4gEp1evXnznO9/h7bff5tlnn2X69On07Nkz3WWdMgpuEQmSmZGbm8uXv/xl5s6dy8svv8z06dPp3r07eXmZfTldBbeIBC8vL4/Ro0czZ84cqqqqmDdvHuXl5UF9LiMnJ4fc3Fz69u3L9773Pfr06XPSbfXmpIhkpN27d7NixQrmzZvHqlWr0l3OCXXr1o3LLruM/Px87rjjDnr27ElBQQFnnnkm48aNo7Ky8oR/eTL7/wkRyVq9e/fm5ptv5qqrrmLLli0sXryYp59+mtra2rTV1K9fP774xS8yZMgQvvvd79K1a1fGjBnT5q/sVXCLSEbr1asXFRUVVFRU8IMf/IBFixbxxBNPsH379pTut6ioiAEDBlBaWsqMGTMwMwYPHkxZWVmHH1tDJSKSVdydzZs3s2jRIpYtW8aePXs6fIGHLl26NJ2WeNlllzF+/HgGDx7MhAkTgOO/s781ysvLTzpUouAWkazU0NBAfX09Tz31FL/61a+orKxs9YU8CgoKyMvLo7y8nEmTJjFw4ECuu+46APLz88nPz+9wfc0Ft4ZKRCQr5ebmUlhYyI033shVV13FihUreOihh3jttdc+970oZtY0Bn3ttdfSt29frrnmGs4991y6deuWloumKLhFJOsVFRVxww03MHnyZHbu3Mm8efPYtm0bEB/6mDhxIhD/nv6CgoJ0lgoouEVEmhQXF1NcXMyDDz6Y7lKapQ/giIgERsEtIhKYFoPbzArM7E0ze9vMNpnZT6P2xWa21czWRdOYqN3MbI6ZVZnZejM7L9WdEBHJJq0Z464HLnH3A2aWD7xmZv8ZrfuJuz9xzPZXAEOj6QJgfnQrIiJJ0OIRt8cdiBbzo6m5k7+vBpZG93sDKDaz0o6XKiIi0MoxbjPLNbN1wE7geXc/+o0tP4uGQ2abWdeorT+wLeHu1VGbiIgkQauC290b3H0MMAA438xGAXcDI4BxQC/gzrbs2MymmVmlmVXu2rWrjWWLiGSvNp1V4u77gJeAye6+PRoOqQd+A5wfbVYDDEy424Co7djHWuDu5e5e3tz3zoqIyOe15qySPmZWHM13Ay4F3j06bm3xb065BtgY3WU5cHN0dsmFwCfuntqv4RIRySKtOaukFFhiZrnEg/5xd3/GzF40sz6AAeuA70XbrwCuBKqAg8C3k1+2iEj2ajG43X09MPYE7ZecZHsHbut4aSIiciL65KSISGAU3CIigVFwi4gERsEtIhIYBbeISGAU3CIigVFwi4gERsEtIhIYBbeISGAU3CIigVFwi4gERsEtIhIYBbeISGAU3CIigVFwi4gERsEtIhIYBbeISGAU3CIigVFwi4gERsEtIhIYBbeISGAU3CIigTF3T3cNmFkdsCXddaRIb2B3uotIgUztF2Ru39SvsAxy9z4nWpF3qis5iS3uXp7uIlLBzCozsW+Z2i/I3L6pX5lDQyUiIoFRcIuIBKazBPeCdBeQQpnat0ztF2Ru39SvDNEp3pwUEZHW6yxH3CIi0kppD24zm2xmW8ysyszuSnc9bWVmj5jZTjPbmNDWy8yeN7O/R7c9o3YzszlRX9eb2Xnpq7x5ZjbQzF4ys3fMbJOZzYjag+6bmRWY2Ztm9nbUr59G7YPNbFVU/2Nm1iVq7xotV0Xrz0pn/S0xs1wzW2tmz0TLmdKvD8xsg5mtM7PKqC3o12JHpDW4zSwX+BVwBTAS+LqZjUxnTe2wGJh8TNtdwAvuPhR4IVqGeD+HRtM0YP4pqrE9YsAd7j4SuBC4LfrZhN63euASdz8XGANMNrMLgQeA2e4+BPgHcEu0/S3AP6L22dF2ndkMYHPCcqb0C2Ciu49JOPUv9Ndi+7l72iagAliZsHw3cHc6a2pnP84CNiYsbwFKo/lS4uepA/wa+PqJtuvsE/A0cGkm9Q0oBNYAFxD/AEde1N70ugRWAhXRfF60naW79pP0ZwDxALsEeAawTOhXVOMHQO9j2jLmtdjWKd1DJf2BbQnL1VFb6ErcfXs0vwMoieaD7G/0b/RYYBUZ0LdoOGEdsBN4HngP2OfusWiTxNqb+hWt/wQ449RW3GoPAv8DaIyWzyAz+gXgwHNmttrMpkVtwb8W26uzfHIyY7m7m1mwp+6YWXfgT8AP3X2/mTWtC7Vv7t4AjDGzYuBJYESaS+owM7sK2Onuq81sQrrrSYHx7l5jZn2B583s3cSVob4W2yvdR9w1wMCE5QFRW+hqzawUILrdGbUH1V8zyyce2r939z9HzRnRNwB33we8RHwIodjMjh7IJNbe1K9o/enAnlNcamv8C/DfzewDYBnx4ZJfEn6/AHD3muh2J/E/tueTQa/Ftkp3cL8FDI3e+e4C3AAsT3NNybAcmBrNTyU+Pny0/eboXe8LgU8S/tXrVCx+aL0I2OzusxJWBd03M+sTHWljZt2Ij9tvJh7gX4s2O7ZfR/v7NeBFjwZOOxN3v9vdB7j7WcR/j150928QeL8AzOw0M+txdB64DNhI4K/FDkn3IDtwJfA34uOM/zPd9bSj/keB7cAR4mNptxAfK3wB+DvwF6BXtK0RP4vmPWADUJ7u+pvp13ji44rrgXXRdGXofQNGA2ujfm0E7o3azwbeBKqAPwJdo/aCaLkqWn92uvvQij5OAJ7JlH5FfXg7mjYdzYnQX4sdmfTJSRGRwKR7qERERNpIwS0iEhgFt4hIYBTcIiKBUXCLiARGwS0iEhgFt4hIYBTcIiKB+f9xxmA4c1QzewAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyGSJ0Yp3JYG"
      },
      "source": [
        "# **Save to video**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SrixcPSNiWd"
      },
      "source": [
        "height, width, layers = env.render(mode='rgb_array').shape\n",
        "size = (width,height)\n",
        "out = cv2.VideoWriter('rl_LunarLander5.mp4',cv2.VideoWriter_fourcc(*'MP4V'), 60, size)\n",
        " \n",
        "for i in range(len(img_array)):\n",
        "    out.write(img_array[i])\n",
        "out.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjFBWwQP1hVe"
      },
      "source": [
        "# 你的成績"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpJpZz3Wbm0X",
        "outputId": "d474f8e5-d1f0-4974-8a3e-9f89b581fa22"
      },
      "source": [
        "print(f\"Your final reward is : %.2f\"%np.mean(test_total_reward))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your final reward is : 252.65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUBtYXG2eaqf"
      },
      "source": [
        "## 參考資料\n",
        "\n",
        "以下是一些有用的參考資料。\n",
        "建議同學們實做前，可以先參考第一則連結的上課影片。\n",
        "在影片的最後有提到兩個有用的 Tips，這對於本次作業的實做非常有幫助。\n",
        "\n",
        "- [DRL Lecture 1: Policy Gradient (Review)](https://youtu.be/z95ZYgPgXOY)\n",
        "- [ML Lecture 23-3: Reinforcement Learning (including Q-learning) start at 30:00](https://youtu.be/2-JNBzCq77c?t=1800)\n",
        "- [Lecture 7: Policy Gradient, David Silver](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/pg.pdf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGqP2EU1joWM"
      },
      "source": [
        ""
      ]
    }
  ]
}